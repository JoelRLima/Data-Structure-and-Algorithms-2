## An√°lise de Redes Complexas na Wikipedia
Este projeto foi desenvolvido como Trabalho __Final da disciplina de Algoritmos e Estrutura de Dados II__. O objetivo √© construir, visualizar e analisar uma rede complexa gerada a partir de artigos da Wikipedia, explorando as conex√µes sem√¢nticas entre diferentes t√≥picos.

> Link do v√≠deo: https://www.youtube.com/watch?v=eA3HfkdZ5gs

> Link da p√°gina web com o grafo: https://joelrlima.github.io/Data-Structure-and-Algorithms-2/Complex%20Structures/network/

### üë• Autores
* Sueyvid

* Joel

* √änio 

## üéØ Objetivo
O notebook tem como objetivo construir uma rede direcionada onde:

* __N√≥s__: S√£o p√°ginas da Wikipedia.

* __Arestas__: S√£o os hiperlinks (refer√™ncias) de uma p√°gina para outra.

O projeto aplica conceitos de teoria dos grafos para analisar a topologia da rede, eliminar duplicatas e focar nos n√≥s mais relevantes atrav√©s de m√©tricas de centralidade .

## üß† A Heur√≠stica de Constru√ß√£o (Snowballing)
Devido ao crescimento exponencial do grafo (Explos√£o Combinat√≥ria), a coleta de dados da __Camada 2 para a Camada 3__ utiliza uma Heur√≠stica H√≠brida de Similaridade Sem√¢ntica para filtrar os links mais relevantes.

Como funciona:

1. __Sementes (Seeds)__: O grafo inicia com t√≥picos centrais definidos manualmente (ex: Complex Network, Artificial Intelligence, Global Warming) .

1. __Filtragem (Blacklist)__: Remove links estruturais irrelevantes como datas, ISBN, identificadores de bibliotecas e categorias de manuten√ß√£o .

1. __Heur√≠stica Centr√≠petra__:

    * Ao expandir um n√≥, o algoritmo calcula a __similaridade textual__ (usando ```difflib.SequenceMatcher```) entre o t√≠tulo da p√°gina atual e seus links.

    * Links com alta similaridade recebem prioridade (Score > 0.4).

1. __Estrat√©gia H√≠brida (Fallback):__

    * O algoritmo tenta preencher ```MAX_LINKS``` (ex: 10) com os melhores candidatos sem√¢nticos.

    * Caso n√£o haja candidatos qualificados suficientes, ele completa as vagas restantes com outros links v√°lidos da p√°gina para garantir a continuidade da expans√£o da rede.

## üõ†Ô∏è Tecnologias Utilizadas
O projeto foi desenvolvido em __Python 3__ utilizando as seguintes bibliotecas:

[__Wikipedia-API__](https://pypi.org/project/wikipedia/): Para crawling e obten√ß√£o dos links das p√°ginas.

[__NetworkX__](https://networkx.org/): Para constru√ß√£o, manipula√ß√£o e c√°lculo de m√©tricas do grafo.

[__Matplotlib__](https://networkx.org/): Para plotagem de histogramas de grau e visualiza√ß√£o de dados.

__Difflib & Re__: Bibliotecas padr√£o para processamento de texto e express√µes regulares.

## üöÄ Como Executar
### Pr√©-requisitos
Instale as depend√™ncias listadas no notebook ou no requirements.txt:

```bash
pip install wikipedia networkx matplotlib
```

### Configura√ß√£o
No in√≠cio do notebook, voc√™ pode ajustar os par√¢metros de controle da rede:

```python
MAX_LINKS = 10     # N√∫mero m√°ximo de filhos por n√≥ (Branching Factor)
LIMIT_LAYER = 3    # Profundidade m√°xima da rede (0 -> 1 -> 2 -> 3)
```

### Exporta√ß√£o dos Dados
Ao final da execu√ß√£o, o script gera histogramas da distribui√ß√£o de graus dos n√≥s  e exporta a rede final (ou o subgrafo principal) para o formato __GraphML__, que pode ser aberto no Gephi ou Cytoscape:

```Python
nx.write_graphml(gsub, "cna.graphml")
```

## üìä Processamento de Dados
O pipeline de dados segue as etapas:

1. __Coleta__: Raspagem dos dados com a heur√≠stica aplicada.

1. __Limpeza__: Remo√ß√£o de self-loops e fus√£o de n√≥s duplicados (ex: "Network" e "Networks") .

1. __Poda (Truncate)__: Gera√ß√£o de um subgrafo contendo apenas o "Core" da rede (n√≥s com grau >= 2) para melhor visualiza√ß√£o .

_Este projeto √© estritamente educacional e utiliza dados p√∫blicos da Wikipedia._



